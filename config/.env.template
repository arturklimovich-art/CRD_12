# ==== LOCAL LLM ====
LLM_PROVIDER=local
LLM_PROFILE=fast
OFFLINE_MODE=true

OPENAI_BASE_URL_LOCAL=http://127.0.0.1:4000
OPENAI_API_KEY_LOCAL=ollama-local
LLM_MODEL_LOCAL=qwen2.5:7b-instruct-q4_K_M
LLM_CTX_LEN_LOCAL=2048
LLM_KV_POLICY=gpu
LLM_BATCH_SIZE=1

# ==== CLOUD LLM (fill manually) ====
OPENAI_BASE_URL_CLOUD=
OPENAI_API_KEY_CLOUD=
LLM_MODEL_CLOUD=

# ==== TELEGRAM (DO NOT COMMIT REAL TOKENS) ====
TELEGRAM_TOKEN=
TELEGRAM_CHAT_ID=
