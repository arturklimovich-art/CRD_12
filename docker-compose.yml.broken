services:
  pgvector:
    image: pgvector/pgvector:pg16
    container_name: crd12_pgvector
    environment:
      POSTGRES_DB: crd12
      POSTGRES_USER: crd_user
      POSTGRES_PASSWORD: crd12
      TZ: Europe/Oslo
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U crd_user -d crd12 -h localhost || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 5s
    volumes:
      - pgdata:/var/lib/postgresql/data
    restart: always

  deepseek_proxy:
    build: ./src/app/deepseek_proxy
    image: crd12_deepseek_proxy_local:latest
    container_name: crd12_deepseek_proxy
    environment:
      TZ: Europe/Oslo
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY}
      DEEPSEEK_MODEL_NAME: deepseek-coder
    ports:
      - "8010:8010"
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8010/health')\""]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s

  engineer_b_api:
    build:
      context: ./src/app/engineer_b_api
      dockerfile: Dockerfile
    image: crd12_engineer_b_api_local:latest
    container_name: crd12_engineer_b_api
    environment:
      TZ: Europe/Oslo
      DATABASE_URL: postgres://crd_user:crd12@pgvector:5432/crd12
      DEEPSEEK_PROXY_URL: http://deepseek_proxy:8010/llm/complete
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      GEMINI_MODEL_NAME: gemini-2.0-flash-exp
      GEMINI_MODEL: gemini-2.0-flash-exp
      LANG: C.UTF-8
      PYTHONIOENCODING: utf-8
      PYTHONDONTWRITEBYTECODE: 1
      PYTHONUNBUFFERED: 1
      PYTHONPATH: /app
      UVICORN_HOST: 0.0.0.0
      UVICORN_PORT: 8000
    volumes:
      - ./docker_volumes/engineer_b_api/patches:/app/workspace/patches
      - ./docker_volumes/engineer_b_api/reports:/app/workspace/reports
      - ./docker_volumes/engineer_b_api/snapshots:/app/workspace/snapshots
      - ./docker_volumes/engineer_b_api/adr:/app/workspace/ADR
      - ./docker_volumes/engineer_b_api/logs:/app/workspace/logs

      SUPERVISOR_PORT: 8030
      S3_ENDPOINT: null
      S3_BUCKET: null
      S3_ACCESS_KEY: null
      S3_SECRET_KEY: null
      S3_SECURE: "1"
      EVENT_SINK: "auto"
      METRICS_PORT: "9108"
    ports:
      - "8001:8000"
      - "8030:8030"
      - "9108:9108"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8030/health')"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    depends_on:
      pgvector:
        condition: service_healthy
      deepseek_proxy:
        condition: service_healthy

  bot:
    build: ./src/bot
    image: crd12_bot_local:latest
    container_name: crd12_bot
    command: python -m tasks.task_manager
    environment:
      SELF_BUILDING_MODE: "true"
      TZ: Europe/Oslo
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
      ENGINEER_B_API_URL: http://engineer_b_api:8000
      DATABASE_URL: postgres://crd_user:crd12@pgvector:5432/crd12
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL_NAME: gpt-5-thinking
      LANG: C.UTF-8
      PYTHONIOENCODING: utf-8
      POSTGRES_USER: crd_user
      POSTGRES_PASSWORD: crd12
      POSTGRES_DB: crd12
      POSTGRES_HOST: pgvector
      POST_DEPLOY_VALIDATE: "true"
      POST_DEPLOY_TIMEOUT_SEC: "60"
      POST_DEPLOY_POLL_SEC: "2"
      POST_DEPLOY_MIN_CONSEC_OK: "2"
    volumes:
      - ./src/bot:/app
    depends_on:
      engineer_b_api:
        condition: service_healthy
    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep python | grep task_manager"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
volumes:
  pgdata:
